{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fugue (Spark, Ray, Dask) Integration\n",
    "\n",
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/whylabs/whylogs/blob/mainline/python/examples/integrations/Fugue_Profiling.ipynb)\n",
    "\n",
    "\n",
    "Hi! Perhaps you're already feeling confident with our library, but you really wish there was an easy way to plug our profiling into your existing **Spark, Dask or Ray** clusters or existing **Databricks, Coiled or Anyscale** platforms. Well, glad you've made it here, because this is what we are going to cover in this example notebook ðŸ˜ƒ\n",
    "\n",
    "If you wish to have other insights on how to use whylogs, feel free to check our [other existing examples](https://github.com/whylabs/whylogs/tree/mainline/python/examples), as they might be extremely useful!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing the extra dependency\n",
    "\n",
    "As we want to enable users to have exactly what they need to use from whylogs, the `pyspark` integration comes as an extra dependency. In order to have it available, simply uncomment and run the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install 'whylogs[fugue]' 'fugue[spark]'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Run Whylogs on ... | Installation Command |\n",
    "|:---|:---|\n",
    "| Any Spark cluster (including Databricks Notebooks) | `pip install 'whylogs[fugue]' 'fugue[spark]'` |\n",
    "| Databricks (remote access) | `pip install 'whylogs[fugue]' 'fugue-cloudprovider[databricks]'` |\n",
    "| Any Ray cluster (including Anyscale Notebooks) | `pip install 'whylogs[fugue]' 'fugue[ray]'` |\n",
    "| Anyscale (remote access) | `pip install 'whylogs[fugue]' 'fugue-cloudprovider[anyscale]'` |\n",
    "| Any Dask cluster | `pip install 'whylogs[fugue]' 'fugue[dask]'` |\n",
    "| Coiled  | `pip install 'whylogs[fugue]' 'fugue-cloudprovider[coiled]'` |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following environment variable should NOT need to be set in your environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"PROTOCOL_BUFFERS_PYTHON_IMPLEMENTATION\"] = \"python\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Constructing a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>a</th>\n",
       "      <th>b</th>\n",
       "      <th>c</th>\n",
       "      <th>d</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>0.533206</td>\n",
       "      <td>xy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>0.230533</td>\n",
       "      <td>z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>0.394869</td>\n",
       "      <td>z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>0.618809</td>\n",
       "      <td>z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>0.474868</td>\n",
       "      <td>xy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>1</td>\n",
       "      <td>b</td>\n",
       "      <td>0.904425</td>\n",
       "      <td>xy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>0.645785</td>\n",
       "      <td>z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "      <td>0.324683</td>\n",
       "      <td>xy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "      <td>0.519711</td>\n",
       "      <td>z</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>z</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    a  b         c   d\n",
       "0   1  a  0.533206  xy\n",
       "1   2  b  0.230533   z\n",
       "2   1  a  0.394869   z\n",
       "3   2  b  0.618809   z\n",
       "4   2  b  0.474868  xy\n",
       ".. .. ..       ...  ..\n",
       "95  1  b  0.904425  xy\n",
       "96  3  a  0.645785   z\n",
       "97  1  a  0.324683  xy\n",
       "98  2  b  0.519711   z\n",
       "99  3  a  0.000055   z\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "n = 100\n",
    "np.random.seed(0)\n",
    "tdf = pd.DataFrame(\n",
    "    dict(\n",
    "        a=np.random.choice([1, 2, 3], n),\n",
    "        b=np.random.choice([\"a\", \"b\"], n),\n",
    "        c=np.random.random(n),\n",
    "        d=np.random.choice([\"xy\", \"z\"], n),\n",
    "    )\n",
    ")\n",
    "tdf.to_parquet(\"/tmp/test.parquet\")\n",
    "tdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Profiling using Whylogs + Fugue\n",
    "\n",
    "The simplest way to use `profile` is equivalent to use `why.log(df).view()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cardinality/est</th>\n",
       "      <th>cardinality/lower_1</th>\n",
       "      <th>cardinality/upper_1</th>\n",
       "      <th>counts/n</th>\n",
       "      <th>counts/null</th>\n",
       "      <th>distribution/max</th>\n",
       "      <th>distribution/mean</th>\n",
       "      <th>distribution/median</th>\n",
       "      <th>distribution/min</th>\n",
       "      <th>distribution/n</th>\n",
       "      <th>...</th>\n",
       "      <th>distribution/stddev</th>\n",
       "      <th>frequent_items/frequent_strings</th>\n",
       "      <th>ints/max</th>\n",
       "      <th>ints/min</th>\n",
       "      <th>type</th>\n",
       "      <th>types/boolean</th>\n",
       "      <th>types/fractional</th>\n",
       "      <th>types/integral</th>\n",
       "      <th>types/object</th>\n",
       "      <th>types/string</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>column</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>a</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000150</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.880000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.807540</td>\n",
       "      <td>[FrequentItem(value='1', est=39, upper=39, low...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>SummaryType.COLUMN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>b</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[FrequentItem(value='a', est=57, upper=57, low...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SummaryType.COLUMN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>c</th>\n",
       "      <td>100.000025</td>\n",
       "      <td>100.0</td>\n",
       "      <td>100.005018</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0.992396</td>\n",
       "      <td>0.499929</td>\n",
       "      <td>0.487838</td>\n",
       "      <td>0.000055</td>\n",
       "      <td>100</td>\n",
       "      <td>...</td>\n",
       "      <td>0.294085</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SummaryType.COLUMN</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000100</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>[FrequentItem(value='xy', est=53, upper=53, lo...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>SummaryType.COLUMN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows Ã— 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        cardinality/est  cardinality/lower_1  cardinality/upper_1  counts/n  \\\n",
       "column                                                                        \n",
       "a              3.000000                  3.0             3.000150       100   \n",
       "b              2.000000                  2.0             2.000100       100   \n",
       "c            100.000025                100.0           100.005018       100   \n",
       "d              2.000000                  2.0             2.000100       100   \n",
       "\n",
       "        counts/null  distribution/max  distribution/mean  distribution/median  \\\n",
       "column                                                                          \n",
       "a                 0          3.000000           1.880000             2.000000   \n",
       "b                 0               NaN           0.000000                  NaN   \n",
       "c                 0          0.992396           0.499929             0.487838   \n",
       "d                 0               NaN           0.000000                  NaN   \n",
       "\n",
       "        distribution/min  distribution/n  ...  distribution/stddev  \\\n",
       "column                                    ...                        \n",
       "a               1.000000             100  ...             0.807540   \n",
       "b                    NaN               0  ...             0.000000   \n",
       "c               0.000055             100  ...             0.294085   \n",
       "d                    NaN               0  ...             0.000000   \n",
       "\n",
       "                          frequent_items/frequent_strings  ints/max  ints/min  \\\n",
       "column                                                                          \n",
       "a       [FrequentItem(value='1', est=39, upper=39, low...       3.0       1.0   \n",
       "b       [FrequentItem(value='a', est=57, upper=57, low...       NaN       NaN   \n",
       "c                                                     NaN       NaN       NaN   \n",
       "d       [FrequentItem(value='xy', est=53, upper=53, lo...       NaN       NaN   \n",
       "\n",
       "                      type  types/boolean  types/fractional  types/integral  \\\n",
       "column                                                                        \n",
       "a       SummaryType.COLUMN              0                 0             100   \n",
       "b       SummaryType.COLUMN              0                 0               0   \n",
       "c       SummaryType.COLUMN              0               100               0   \n",
       "d       SummaryType.COLUMN              0                 0               0   \n",
       "\n",
       "        types/object types/string  \n",
       "column                             \n",
       "a                  0            0  \n",
       "b                  0          100  \n",
       "c                  0            0  \n",
       "d                  0          100  \n",
       "\n",
       "[4 rows x 28 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from whylogs.api.fugue import profile\n",
    "\n",
    "profile(tdf).to_pandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now assuming you want to use Spark to profile the dataset distributedly and assuming this is how you get a SparkSession:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/18 21:30:50 WARN Utils: Your hostname, codespaces-5144a4 resolves to a loopback address: 127.0.0.1; using 172.16.5.4 instead (on interface eth0)\n",
      "22/09/18 21:30:50 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/09/18 21:30:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to profile the pandas df on Spark:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<whylogs.core.view.dataset_profile_view.DatasetProfileView at 0x7f593b4fc6d0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile(tdf, engine=spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to profile a SparkDataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<whylogs.core.view.dataset_profile_view.DatasetProfileView at 0x7f593a7e79a0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark_df = spark.createDataFrame(tdf)\n",
    "profile(spark_df, engine=spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also directly profile a parquet file or a folder of parquet files locally or on the cloud (the file will be loaded distributedly):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<whylogs.core.view.dataset_profile_view.DatasetProfileView at 0x7f593a789030>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile(\"/tmp/test.parquet\", engine=spark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WIP!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 ('.venv': poetry)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "vscode": {
   "interpreter": {
    "hash": "d4bce4e749e5452baa925b5367e0ce1a24e1936540311006e3497d016ec67e64"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
